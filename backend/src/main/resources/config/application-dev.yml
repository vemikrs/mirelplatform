# application-dev.yml - Development Environment Configuration
# PostgreSQL (docker-compose.dev.yml) を使用
spring:
  # Spring AI autoconfigure を無効化（Mira独自の設定で制御）
  ai:
    model:
      chat: none
      embedding: none
      image: none
      moderation: none
      audio:
        speech: none
        transcription: none
    vertex:
      ai:
        gemini:
          project-id: dev-dummy-project
          location: us-central1
          chat:
            options:
              model: ${GEMINI_MODEL}
  datasource:
    url: jdbc:postgresql://localhost:5432/mirelplatform
    driver-class-name: org.postgresql.Driver
    username: mirel
    password: mirel
  jpa:
    database-platform: org.hibernate.dialect.PostgreSQLDialect
    hibernate:
      ddl-auto: update # データは保持されます。create-dropにすると起動時に消えます。
    # 起動時の data.sql などの実行を抑制
    sql:
      init:
        mode: never
    properties:
      hibernate:
        jdbc:
          lob:
            non_contextual_creation: true
    show-sql: true
  # Spring Boot Mail設定（JavaMailSender Bean生成用）
  mail:
    host: localhost
    port: 1025
    properties:
      mail:
        smtp:
          auth: false
          starttls:
            enable: false
  # 開発環境用OAuth2設定（ダミー値で設定エラー回避）
  security:
    oauth2:
      client:
        registration:
          github:
            client-id: Iv23liIwxlvNGfAn9K1s
            client-secret: ${GITHUB_CLIENT_SECRET}

logging:
  level:
    jp.vemi.mirel: DEBUG
    jp.vemi.framework: DEBUG
    jp.vemi.ste: DEBUG
    jp.vemi.mirel.apps.mira: DEBUG
    request: DEBUG
    auth: DEBUG
    org.springframework.security: DEBUG
    org.springframework.ai: DEBUG
    org.springframework.web.reactive.function.client: DEBUG

mirel:
  storage-dir: ./data/storage
  stencil:
    layers:
      user: ${mirel.storage-dir}/apps/promarker/stencil/user
      standard: ${mirel.storage-dir}/apps/promarker/stencil/standard
      samples: classpath:/promarker/stencil/samples
    auto-deploy-samples: true
  apps:
    mste:
      # 開発環境: 起動時にステンシルマスタをリロード（Upsertロジックに変更済み）
      # クラスパス変更・ファイル更新を即座に反映
      auto-reload-stencil-on-startup: true

# Development-only: Security configuration for SaaS authentication testing
# CSRF is disabled for development convenience
# In production, set enabled=true and csrf-enabled=true
mipla2:
  security:
    api:
      enabled: true # SaaS認証テスト用に有効化
      csrf-enabled: false # 開発時はCSRF無効（本番では true）

# JWT authentication method (default in WebSecurityConfig)
auth:
  method: jwt # JWT認証を利用
  jwt:
    enabled: true # JWT有効化

# JWT秘密鍵(開発用固定値)
jwt:
  secret: dGVzdC1zZWNyZXQta2V5LWZvci1kZXZlbG9wbWVudC1vbmx5LTEyMzQ1Njc4OTBhYmNkZWY=

# 開発環境用OTP設定 (有効期限を長めに、E2Eテスト考慮)
otp:
  expiration-minutes: 10
  resend-cooldown-seconds: 10 # 再送信クールダウン(秒)

# 開発環境用レート制限 (緩和 - E2Eテスト考慮)
rate-limit:
  otp:
    request-per-minute: 6 # 60秒間に6回までリクエスト可能
    verify-per-minute: 20

# 開発環境用メール設定 (MailHog)
# 注: spring.mail は JavaMailSender Bean 生成用
# email.provider は アプリケーション層のメール送信先制御用
email:
  provider: smtp
  smtp:
    host: localhost
    port: 1025

# Mira AI 設定（開発環境）
# Spring AI autoconfigure は spring.ai.model.chat=none で無効化済み
# このアプリ独自の設定で AI 機能を制御
mira:
  ai:
    enabled: true # Mira AI 機能を有効化
    # 開発環境のデフォルトとしてMock AIを使用。
    # 実際のAIを使用する場合は環境変数 MIRA_AI_PROVIDER で上書き可能 (例: export MIRA_AI_PROVIDER=vertex-ai-gemini)
    provider: ${MIRA_AI_PROVIDER:vertex-ai-gemini}
    mock:
      enabled: true # Mock AI を有効化
    vector:
      search-threshold: 0.6 # ベクトル検索閾値 (0.0: 全検索, 1.0: 完全一致) - 不具合時は0.0に緩和可能
      response-delay-ms: 300 # 応答遅延シミュレーション
      default-response: "ご質問ありがとうございます。現在開発環境のためモックで応答しています。"

    # Vertex AI (Gemini) 設定
    vertex-ai:
      project-id: ${GEMINI_PROJECT_ID:dev-dummy-project}
      location: ${GEMINI_LOCATION:us-central1}
      model: ${GEMINI_MODEL:gemini-2.5-flash}

    # GitHub Models 設定（開発環境でローカルテスト用）
    # 参考: https://docs.github.com/en/rest/models/inference
    # `gh auth token` で取得したトークンを環境変数 GITHUB_TOKEN に設定
    # PAT には models:read パーミッションが必要
    github-models:
      api-key: ${GITHUB_TOKEN:}
      # 新しい GitHub Models REST API エンドポイント (2025年更新)
      # Spring AI OpenAiApi は {base-url}/chat/completions にアクセスするため
      # base-url は /inference まで指定
      base-url: https://models.github.ai/inference
      # モデルID形式: {publisher}/{model_name} (すべて小文字)
      # 利用可能モデル: https://models.github.ai/catalog/models
      # NOTE: Llama 3.3 は tool_calls 時に content:null 必須で 500 エラーになるため OpenAI モデルを使用
      model: ${GITHUB_MODELS_MODEL:openai/gpt-5-mini}
      temperature: 0.7
      max-tokens: 4096
      timeout-seconds: 60
    # Azure OpenAI 設定（本番/ステージング環境用）
    azure-openai:
      endpoint: ${AZURE_OPENAI_ENDPOINT:}
      api-key: ${AZURE_OPENAI_API_KEY:}
      deployment-name: gpt-4o
      temperature: 0.7
      max-tokens: 4096
      timeout-seconds: 60
